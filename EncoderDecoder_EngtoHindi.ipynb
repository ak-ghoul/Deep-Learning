{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EncoderDecoder_Architecture.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ak-ghoul/Deep-Learning/blob/master/EncoderDecoder_EngtoHindi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAVpkGgBUHPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import string\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSKq5WiVVkOk",
        "colab_type": "code",
        "outputId": "b726cf57-a217-44f1-a0cd-126881813e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_letters = string.ascii_uppercase\n",
        "print(all_letters)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GveDAiU8XpOr",
        "colab_type": "code",
        "outputId": "9a42eb52-b2eb-477c-a4b5-4f87a85e9ff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "pad_char = '-PAD-'\n",
        "eng_letter_index = {}\n",
        "eng_letter_index[pad_char] = 0\n",
        "for index, letter in enumerate(all_letters):  # always use enumerate whenever dealing with indices & values of ant data structure in python\n",
        "  eng_letter_index[letter] = index + 1\n",
        "print(eng_letter_index)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27RyMxO2cOCW",
        "colab_type": "code",
        "outputId": "eaf2713e-7f86-450f-ab6f-97ff6104835d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432   |   Source : https://asecuritysite.com/coding/asc2?val=2304%2C2560\n",
        "\n",
        "hindi_letter_index = {}\n",
        "hindi_letter_index[pad_char] = 0\n",
        "c = 1\n",
        "for i in range(2304, 2432):\n",
        "  hindi_letter_index[chr(i)] = c\n",
        "  c += 1\n",
        "print(hindi_letter_index)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpiQ5PiGfcZI",
        "colab_type": "code",
        "outputId": "3aa781e0-92fb-4a8a-ad07-d77af5ce22e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re \n",
        "non_eng_letters_regx = re.compile('[^a-zA-Z ]') # space at last ensures space b/w words will be retained\n",
        "print(non_eng_letters_regx)\n",
        "\n",
        "# Remove all English non-letters\n",
        "def del_noneng_letters(line):\n",
        "  line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "  line = non_eng_letters_regx.sub('', line)   # substitute anything which is not in [^a-zA-Z ] in the line with nothing i.e. remove em\n",
        "  return line.split()\n",
        "\n",
        "def del_nonhindi_letters(line):\n",
        "  line = line.replace('-', ' ').replace(',', ' ')\n",
        "  clean_hindi_line = ''\n",
        "  for letter in line:\n",
        "    if letter in hindi_letter_index or letter == ' ':\n",
        "      clean_hindi_line += letter\n",
        "  return clean_hindi_line.split()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "re.compile('[^a-zA-Z ]')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2qzLoXzy7PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):            # class to deal with xml dataset\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, del_nonhindi_letters)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()   # the root tag of the xml file is transliterationCorpus\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = del_noneng_letters(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GHeP7hzvvcC",
        "colab_type": "code",
        "outputId": "baaf31b7-8bbc-4d74-ff09-a7be1ac76ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "train_set = TransliterationDataLoader('rI58TOlAScioEuPBbOYh_NEWS2012TrainingEnHi13937-1563719470862.xml')\n",
        "test_set = TransliterationDataLoader('njThAK0RQGeoOuE9rfwg_NEWS2012RefEnHi1000-1563719263404.xml')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S6VIqAGHWpe",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCEjQvUlwt7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_engword_rep(word):        # converting input word to one hot representation\n",
        "  oh_input_vector = torch.zeros(len(word)+1, 1, len(eng_letter_index)).to(device)  # one xtra is taken on x axis to put pad at last x index\n",
        "  for index, letter in enumerate(word):\n",
        "    pos = eng_letter_index[letter]\n",
        "    oh_input_vector[index][0][pos] = 1\n",
        "  pad_pos = eng_letter_index[pad_char]\n",
        "  oh_input_vector[index+1][0][pad_pos] = 1\n",
        "  return oh_input_vector\n",
        "\n",
        "def output_hindiword_rep(word):   # converting output hindi characters to tensors.     O/P is not converted into one hot, only input\n",
        "  output_hindi_index_tensor = torch.zeros([len(word)+1, 1], dtype = torch.long).to(device)   # no 3d, 2d because conversion to tensors no OH\n",
        "  for index, letter in enumerate(word):\n",
        "    pos = hindi_letter_index[letter]\n",
        "    output_hindi_index_tensor[index][0] = pos\n",
        "  pad_pos = hindi_letter_index[pad_char]\n",
        "  output_hindi_index_tensor[index+1][0] = 0\n",
        "  return output_hindi_index_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRa4OjVvQK-L",
        "colab_type": "code",
        "outputId": "b8738bee-eca8-413a-82de-e08a4d0f3b9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "eng, hindi = train_set.get_random_sample()  # if random val from a dataset required. | np.random only when b/w range is known\n",
        "print(eng, hindi)\n",
        "print(input_engword_rep(eng))\n",
        "print(output_hindiword_rep(hindi))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PHOTOGRAPHY फोटोग्राफी\n",
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n",
            "tensor([[44],\n",
            "        [76],\n",
            "        [32],\n",
            "        [76],\n",
            "        [24],\n",
            "        [78],\n",
            "        [49],\n",
            "        [63],\n",
            "        [44],\n",
            "        [65],\n",
            "        [ 0]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saW-BYOERgXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, verbose = False):\n",
        "    super(Transliteration_EncoderDecoder, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "    self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)   # final o/p of decoder is given as  \n",
        "\n",
        "    self.h2o = nn.Linear(hidden_size, output_size)   # hidden to output\n",
        "    self.SoftMax = nn.LogSoftmax(dim = 2)\n",
        "\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "    # encoder\n",
        "    output, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Encoder input :', input.shape)\n",
        "      print('Encoder output :', output.shape)\n",
        "      print('Encoder hidden :', hidden.shape)\n",
        "    \n",
        "    # decoder\n",
        "    decoder_state = hidden\n",
        "    decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "    outputs = []\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Decoder state :', decoder_state.shape)\n",
        "      print('Decoder input :', decoder_input.shape)\n",
        "\n",
        "    for i in range(max_output_chars):\n",
        "      out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "    \n",
        "      out = self.h2o(decoder_state)  # to convert the dimensions of the decoder_state\n",
        "      out = self.SoftMax(out)\n",
        "      outputs.append(out.view(1, -1))\n",
        "\n",
        "      max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "      if not ground_truth is None:\n",
        "        max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "      one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "      one_hot.zero_()\n",
        "      one_hot.scatter_(2, max_idx, 1)\n",
        "            \n",
        "      decoder_input = one_hot.detach()  # detach is done to stop calculating gradients for the connections when output is passed to next hidden layer\n",
        "      # gradient of every connection is calculated from the backward pass but calculation of these new connections decreases efficiency\n",
        "      \n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp6svqcl4aSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_letter_index), 256, len(hindi_letter_index), True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4zo3zodORss",
        "colab_type": "text"
      },
      "source": [
        "##  Attention Encoder Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSJF6LWwCY7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, verbose = False):\n",
        "    super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "    self.hidden_size = hidden_size   # self assigned to use it outside init in other funcs\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "    self.decoder_rnn_cell = nn.GRU(hidden_size * 2, hidden_size)   # 2*hidden because one from attention & other from decoder output. doubles the size\n",
        "\n",
        "    self.h2o = nn.Linear(hidden_size, output_size)  \n",
        "    self.SoftMax = nn.LogSoftmax(dim = 2)\n",
        "\n",
        "    self.verbose = verbose\n",
        "\n",
        "    self.U = nn.Linear(hidden_size, hidden_size)     # e(j, t) = Vattn. * tanh(Uattn. * h + Wattn. * s) \n",
        "    self.W = nn.Linear(hidden_size, hidden_size)    \n",
        "    self.attn = nn.Linear(hidden_size, 1)    # self.attn is Vattn. from equation\n",
        "    self.o2h = nn.Linear(output_size, hidden_size)   #  for calculation of attention vector\n",
        "\n",
        "  def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "    # encoder\n",
        "    encoder_output, hidden = self.encoder_rnn_cell(input)\n",
        "    encoder_output = encoder_output.view(-1, self.hidden_size)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Encoder Output', encoder_output.shape)\n",
        "\n",
        "    # decoder\n",
        "    decoder_state = hidden   # initial decoder state is assigned hidden from the encoder. That connection encoder -> decoder\n",
        "    decoder_input = torch.zeros(1, 1, self.output_size).to(device)  # initial decoder input is all 0's tensor. later one hot passes from decoder_output\n",
        "\n",
        "    outputs = []\n",
        "    U = self.U(encoder_output)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Decoder State:', decoder_state.shape)\n",
        "      print('Decoder Input:', decoder_input.shape)\n",
        "      print('U * Encoder Output:', U.shape)\n",
        "\n",
        "    for i in range(max_output_chars):\n",
        "\n",
        "      W = self.W(decoder_state.view(1, -1).repeat(encoder_output.shape[0], 1))\n",
        "      V = self.attn(torch.tanh(U + W))\n",
        "      attn_weights = F.softmax(V.view(1, -1), dim = 1)\n",
        "\n",
        "      attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_output.unsqueeze(0))  # batch matrix multiplication. \n",
        "      # unsqueeze makes(x,) as (1, x) if 0 is passed else (x, 1)\n",
        "      embedding = self.o2h(decoder_input)\n",
        "      decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0) # 1 states dimension along which concatenate\n",
        "\n",
        "      out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "      if self.verbose:\n",
        "        print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "      out = self.h2o(decoder_state)\n",
        "      out = self.SoftMax(out)\n",
        "      outputs.append(out.view(1, -1))\n",
        "        \n",
        "      if self.verbose:\n",
        "        print('Decoder output', out.shape)\n",
        "        self.verbose = False\n",
        "            \n",
        "      max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "      if not ground_truth is None:\n",
        "        max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "      one_hot = torch.zeros(out.shape, device=device)\n",
        "      one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "      decoder_input = one_hot.detach()\n",
        "            \n",
        "    return outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jcLIQGdNV4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_letter_index), 256, len(hindi_letter_index), verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK-CFI6eOrPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "\n",
        "  net.train().to(device)\n",
        "  opt.zero_grad()\n",
        "  eng_word, hindi_word = train_set.get_batch(batch_size)\n",
        "\n",
        "  total_loss = 0\n",
        "  for i in range(batch_size):\n",
        "    input_oh = input_engword_rep(eng_word[i])\n",
        "    output_tensor = output_hindiword_rep(hindi_word[i])\n",
        "    outputs = net(input_oh, output_tensor.shape[0], device, output_tensor if teacher_force else None)\n",
        "\n",
        "    for index, output in enumerate(outputs):\n",
        "      loss = criterion(output, output_tensor[index]) / batch_size\n",
        "      loss.backward(retain_graph = True)\n",
        "      total_loss += loss\n",
        "    \n",
        "  opt.step()\n",
        "  return total_loss/batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7oWtleyeErS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)  # used to clear the previous graph\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYVKd15KfhgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_letter_index), 256, len(hindi_letter_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8JjGu235iOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a750213-4560-4133-ca35-9002d9d5f1b1"
      },
      "source": [
        "print(device)\n",
        "sb.set()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkc_5bfi4L29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "98373a39-65e7-419c-df1c-cc08d942497f"
      },
      "source": [
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.17757657170295715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wcdUzGZCi0dDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.49726164, 0.49805546, ..., 0.17760351, 0.17757657,\n",
              "       0.1775367 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMxBFJuM4hPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_letter_index), 256, len(hindi_letter_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUs-xyMo7QhD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "outputId": "e851adf7-cddb-4b20-fc09-7805b5dbd4a5"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.1446012556552887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEMCAYAAADqG+D0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder_Attention. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AltD0Z5T7Tq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_set)):\n",
        "        eng, hindi = test_set[i]\n",
        "        gt = output_hindiword_rep(hindi)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_set)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH__MuQ9ml99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmXy_-9fmuHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}